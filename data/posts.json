[
  {
    "id": 1767107488948,
    "title": "Conversationalist AI",
    "content": "I built a voice-activated AI system that runs at approximately 0.18-0.58 seconds per LLM response using local hardware (Intel i7-14700KF, NVIDIA RTX 4060 Ti, 32GB RAM). The system features real-time voice transcription via OpenAI Whisper, persistent conversation memory in PostgreSQL, secure bcrypt authentication with voice-based user ID login, and natural text-to-speech output via pyttsx3. Currently deployed locally with plans for embedded hardware implementation (Raspberry Pi 5) and future machine learning enhancements for voice recognition and behavioral pattern analysis.\n\nThis project is structured in multiple parts. First, I'll walk through the system architecture and core services (audio, database, authentication, LLM integration, and TTS). Then, I'll cover the technical challenges I faced—particularly around database schema design, dependency management, and robust error handling for transcription failures. Finally, I'll outline the roadmap for hardware deployment and machine learning integration to create a truly intelligent \"desk companion\" capable of learning user preferences, voice patterns, and behavioral context.\n\n\nPart 1: System Architecture\nSection 1.1: Core Services Overview\nThe system is built on five core services that work together: \n\nAudioService handles all voice input/output operations. It uses PyAudio for capturing 16kHz mono audio streams at 1024-byte chunks, records audio segments to WAV files, and interfaces with OpenAI's Whisper model for speech-to-text transcription. The service implements automatic retry logic for transcription failures and saves all audio recordings to timestamped files for future voice training.\n\nDatabaseService manages PostgreSQL connections and all data persistence. It maintains two primary tables: users (storing user_id, bcrypt password hashes, timestamps, failed login attempts, and JSONB metadata for future ML features) and conversations (storing full conversation history with UUIDs, user associations, timestamps, audio file paths, and both user input and AI responses). \n\nAuthService provides secure user authentication. It implements bcrypt password hashing with automatic salt generation, normalizes passwords (lowercase + strip whitespace) for consistent voice-to-text variations, and supports both registration and login flows. The service tracks failed login attempts and maintains last_seen timestamps for user activity monitoring.\n\nLLMService interfaces with Ollama for local LLM inference. Currently configured with llama3.1:8b, it builds complete conversation context from database history, formats messages for the chat API, and implements a system prompt that establishes the AI's personality as an intelligent desk assistant. Response generation typically takes 0.18-0.58 seconds depending on context length.\n\nTTSService converts AI responses to natural speech using pyttsx3. The service configures speech rate at 165 WPM and volume at 0.9, supports multiple voice profiles, and provides real-time audio feedback during user interactions.\n\nSection 1.2: Authentication Flow\nThe authentication system uses voice-based user ID input combined with spoken passwords. When a user first interacts with the system, they speak a 4-digit user ID which is transcribed and parsed through a parser that handles multiple formats:\n\t• Direct digits: \"1234\" → 1234\n\t• Spelled out: \"one two three four\" → 1234\n\t• Mixed format: \"12 thirty four\" → 1234\nThe parse_user_id() function normalizes transcriptions by mapping common speech-to-text variations (won→1, to/too→2, for/fore→4, ate→8, etc.) and extracts valid 4-digit integers within the 1000-9999 range. This handles the inherent ambiguity of voice input while maintaining security.\nIf the user ID exists, the system prompts for password verification with unlimited attempts. New users create an account by speaking a password phrase which is normalized and hashed with bcrypt before storage. This approach balances security (bcrypt + salting) with usability (voice-based interaction).\n\nSection 1.3: Conversation Loop Architecture\nOnce authenticated, users enter a continuous conversation loop. The system:\n\t1. Captures voice input \n\t2. Transcribes speech using Whisper \n\t3. Builds conversation context by loading ALL past conversations from PostgreSQL and formatting them as message history for the LLM\n\t4. Generates AI response through Ollama with full context awareness\n\t5. Speaks the response via TTS\n\t6. Persists the exchange to the database with UUID, timestamps, and audio file paths\nExit commands (\"goodbye\", \"exit\", \"quit\", \"logout\", \"bye\") are detected through keyword matching and gracefully terminate the session.\n\n\nPart 2: Technical Challenges & Solutions\nChallenge 2.1: Database Schema Evolution\nProblem: My initial schema had a generic users table with just a name field, which didn't support the authentication system I was building. I needed to migrate to a proper authentication schema while preserving the ability to add ML features later.\nSolution: I created a migration script that drops old tables and rebuilds from a new schema.sql. The new schema uses user_id INTEGER PRIMARY KEY for 4-digit voice IDs, stores bcrypt password_hash, tracks security metrics (failed_attempts, last_seen), and includes BYTEA fields for future voice/face embeddings and JSONB metadata for flexible ML feature storage. This schema supports the current authentication flow while being extensible for ML enhancements.\n\nChallenge 2.2: Voice Input Parsing Reliability\nProblem: Whisper transcription of spoken numbers is inconsistent. A user saying \"1234\" might get transcribed as \"one two three four\", \"twelve thirty-four\", \"1 2 3 4\", or various other formats. This made authentication unreliable.\nSolution: I think it is simply easier to show you. I created a parser with multiple fallback strategies:\n\n~~~~~CODE SNIIPET~~~~~\ndef parse_user_id(transcription: str) -> Optional[int]:\n    # Try direct int conversion first\n    try:\n        user_id = int(text)\n        if 1000 <= user_id <= 9999:\n            return user_id\n    except ValueError:\n        pass\n    \n    # Map words to digits (handles homophones)\n    word_to_digit = {\n        'zero': '0', 'oh': '0',\n        'one': '1', 'won': '1',\n        'two': '2', 'to': '2', 'too': '2',\n        # ... full mapping\n    }\n    \n    # Replace words with digits\n    for word, digit in word_to_digit.items():\n        text = text.replace(word, digit)\n    \n    # Extract digits and validate range\n    digits_only = ''.join(c for c in text if c.isdigit())\n~~~~~CODE SNIIPET~~~~~\n\nChallenge 2.3: LLM Context Management\nProblem: Initially, I misunderstood how LLMs maintain context. I thought Ollama would \"remember\" conversations automatically. When the AI couldn't recall past interactions, I realized LLMs are stateless—they need explicit context on every request.\nSolution: I implemented build_conversation_history() which loads the user's complete conversation history from PostgreSQL and formats it as a message array for Ollama's chat API. This includes:\n\t• System prompt defining AI personality and capabilities\n\t• All past user inputs and AI responses in chronological order\n\t• Current user input\nThe LLM now has perfect recall because we explicitly provide all context. This was a key learning moment about LLM architecture—they don't \"train\" during conversations; they simply process the context window we provide.\n\nChallenge 2.4: Whisper Transcription Failures\nProblem: Whisper occasionally fails to transcribe audio, especially with background noise or unclear speech. This would crash the authentication flow.\nSolution: I implemented retry logic and empty transcription handling:\n\n~~~~~CODE SNIIPET~~~~~\ndef record_and_transcribe(self, duration=5):\n    filepath = self.record_audio(duration)\n    text = self.transcribe_audio(filepath)\n    return {'audio_path': filepath, 'text': text}\n\n# In conversation loop:\nresult = audio.record_and_transcribe(duration=5)\nuser_input = result['text'].strip()\n\nif not user_input:\n    print(\"⚠️  No input detected. Try again.\")\n    tts.speak(\"I didn't hear anything. Please try again.\")\n    continue\n~~~~~CODE SNIIPET~~~~~\nThe system now gracefully handles transcription failures by prompting the user to try again rather than crashing\n\n\nPart 3: Performance & Metrics\nPart 3.1: Response Time Analysis\nThe system's current local performance:\n\t• Whisper transcription: ~2-4 seconds for 5-second audio clips\n\t• LLM inference: 0.18-0.58 seconds (varies with context length)\n\t• TTS generation: ~1-2 seconds for typical responses\n\t• Database operations: <0.01 seconds for conversation storage/retrieval\n\t• Total user experience: ~3-7 seconds from speech to AI response\n\nPart 3.2: Memory & Storage Efficiency\nCurrent resource usage on local hardware:\n\t• RAM: ~8GB during active conversation (Whisper model + LLM + OS overhead)\n\t• VRAM: ~6GB for llama3.1:8b model\n\t• Storage: ~500KB per conversation (audio WAV files + database records)\n\t• Database size: Minimal (<1MB for 100+ conversations with indices)\nThe PostgreSQL database with JSONB metadata fields provides flexibility for future ML features without restructuring the schema. Audio files are stored separately with paths in the database, enabling future voice recognition training.\n\nPart 4: What's Next\nPart 4.1: Hardware Deployment\nThe current local implementation proves the architecture works, but the end goal is a portable, always-on \"desk companion.\" I'm planning to deploy to embedded hardware utilizing a Raspberry Pi 5. \n\nI want to eventually scale this project into having real-time vision as well. Amongst other things, this project will become my security system at my house. I want to be able to train the model to learn faces… knows when I enter the home versus an intruder. Also, I would eventually like to purchase numerous hardware components and set them up in different rooms in the house. I can start the conversation in the garage, and pick up the conversation into the living room as the user is on the move. \n\nThe embedded deployment will enable 24/7 operation, voice activation (wake word detection), and physical portability—transforming it from a desktop application into a true intelligent assistant.\n\nPart 4.2: Machine Learning Enhancements\nThe current system uses rule-based parsing and pre-trained models, but there's significant room for ML improvements:\nML Enhancement 1: Voice Recognition & Authentication\nCurrent limitation: User authentication requires typing ENTER before speaking, and the system doesn't recognize individual voice characteristics.\nML solution: Train a speaker verification model using stored audio files from conversations.audio_path. Implement:\n\t• Voice embedding extraction using models like x-vector or SpeechBrain\n\t• Store embeddings in the users.voice_embedding BYTEA field\n\t• Continuous authentication during conversations (detect if a different person starts speaking)\n\t• Wake word detection to eliminate ENTER key requirement\nThis would enable true hands-free operation and biometric security.\nML Enhancement 2: Conversation Context Prediction\nCurrent limitation: The system loads ALL past conversations on every turn, which will become inefficient with large histories (1000+ conversations).\nML solution: Implement a conversation relevance model:\n\t• Use sentence embeddings (Sentence-BERT) to encode past conversations\n\t• Build a vector similarity search (FAISS or pgvector) to retrieve only relevant past messages\n\t• Train a lightweight classifier to predict which conversations are contextually relevant\n\t• Reduce context window size while maintaining \"memory\" quality\nThis keeps inference fast while scaling to years of conversation history.\nML Enhancement 3: Behavioral Pattern Analysis\nCurrent limitation: The AI treats every session identically and doesn't learn user preferences or habits.\nML solution: Add behavioral modeling:\n\t• Time-series analysis of conversation patterns (when user typically interacts, common topics, preferred response styles)\n\t• Sentiment analysis to detect user mood and adjust AI personality accordingly\n\t• Topic modeling to identify user interests over time\n\t• Store learned patterns in users.metadata JSONB field\n\t• Use reinforcement learning to optimize response quality based on conversation length and user engagement\nThis transforms the system from a stateless chatbot into a truly adaptive assistant.\nML Enhancement 4: Improved Speech Parsing\nCurrent limitation: The parse_user_id() function uses hardcoded rules and may miss edge cases.\nML solution: Fine-tune a small sequence-to-sequence model specifically for number transcription correction:\n\t• Collect labeled training data from actual Whisper transcriptions → correct user IDs\n\t• Train a T5-small or BERT model to map transcriptions to normalized IDs\n\t• Deploy alongside Whisper for real-time correction\n\t• Extend to general voice command understanding (beyond just user IDs)\nThis would make voice authentication even more reliable across accents and speaking styles.",
    "category": "tech",
    "created": "2025-12-30T15:11:28.948Z",
    "lastModified": "2025-12-30T15:11:28.948Z",
    "pinnedSlots": {
      "discourse": null,
      "tech": 2,
      "history": null,
      "literature": null
    }
  },
  {
    "id": 1767107281461,
    "title": "Chess Engine + ML",
    "content": "I built a chess engine in C++ that plays at approximately 1500 ELO using both classical search algorithms and modern machine learning. The engine has two evaluation modes: a classical engine using hand-crafted evaluation with NegaMax search, Alpha-Beta pruning, and quiescence search, and a neural network trained on over 1 million (change!!) chess positions from Lichess games. \n\nThis post is structured in two parts. First, I'll walk through the classical engine architecture - the core algorithms, move ordering optimizations, and debugging challenges that taught me as much about software engineering as they did about chess. Then, I'll cover the machine learning pipeline: data collection and preprocessing, neural network architecture, training on 1M positions(change!!!), and the production integration using PyTorch and ONNX Runtime to deploy the model in C++.\n\nYou can try both engines at [ENTER URL] - the interface lets you toggle between classical and neural network evaluation modes to compare their playing styles.\n\n\nPart 1: Core Search Architecture \n\nSection 1.1:  NegaMax with Alpha-Beta Pruning - The Core Algorithm\nThe foundation of the classical engine is NegaMax. Instead of alternating between maximizing and minimizing perspectives, NegaMax always maximizes from the current player's viewpoint by negating the opponent's score. Next, we have Alpha-beta pruning which represents the best score we've guaranteed so far (lower bound), while beta is the opponent's best alternative (upper bound). If we find a move scoring >= beta, the opponent will avoid this position, so we can stop searching this branch entirely. This cuts the search tree by 50-75%, letting the engine search 2-3 plies deeper.\n\nSection 1.2:  Quiescence Search - Avoiding Tactical Blindness\nMoving further, we implemented quiescence search in order to avoid the horizon effect. The horizon effect is when the engine doesn't search far enough depth wise during tactical sequences. Why? Because it sees a good move and plays it - without seeing what comes soon after that move. This can lead to bad play by the engine. To negate this I implemented quiescence search that extends beyond the nominal depth, examining only tactical moves until the position becomes quiet. With this, I integrated delta pruning. This ensures that captures are skipped that can't improve the position. For example, If the current position evaluates to -200, and we can capture a pawn worth +100, the best we could hope for is -100. But if alpha is already +50 (we've found a line guaranteeing us +50), this capture is futile - it can't possibly beat what we already have. So we skip it.\n\nSection 1.3:  Transposition Tables - Eliminating Redundant Work \nAnother piece to the puzzle was implementing a transposition table. Chess positions can transpose - reach the same position through different move orders. A transposition table is a massive hash table (1M+ entries) that caches position evaluations to avoid redundant work. The table uses Zobrist hashing - a technique where each piece on each square has a random 64-bit number. The position's hash is the XOR of all these numbers, making hash updates O(1) during move make/unmake.\n\n\nPart 2:  Move Ordering \n\nAlpha-beta pruning's effectiveness depends entirely on examining good moves first. With optimal move ordering, the first move causes a beta cutoff 50-60% of the time. With poor ordering, this drops to 10-20%, forcing the engine to search 3-5x more positions. In order to improve upon this I implemented a multi-tier move ordering system: \n\t1. Transposition Table Move (highest priority) \n\t\tÃ¢ÂÂ If we've seen this position before, try the best move from that search first.\n\t2. Static Exchange Evaluation (SEE) for Captures \n\t\tÃ¢ÂÂ Not all captures are good. SEE simulates the complete capture sequence to determine net material .\n\t3. Killer Moves\n\t\tÃ¢ÂÂ This heuristic (did I say this right) remembers quiet moves that caused beta cutoffs at the same depth in sibling branches. If Nf3 caused a cutoff in one line, it's likely strong in similar positions. Each depth stores 2 killer moves. \n\t4. History Heuristic \n\t\tÃ¢ÂÂ Tracks how often each move (from-square to to-square) has caused beta cutoffs across the entire search. Squaring the depth gives more weight to stronger moves that work deeper in the tree.\n\nPart 3:  Position Evaluation \n\nOnce the search reaches a leaf node, the evaluation function determines \"how good is this position?\" This is where we teach the engine what makes a chess position strong or weak. For example, a knight on the rim is worth maybe 280, whereas a centralized knight is worth 360.\n\nPawn Structure \n\t- Doubled pawns:  -10 penalty\n\t- Isolated pawns:  -15 penalty \n\t- Passed pawns:  +20-50 depending on how advanced \n\nKing Safety \n\t- Castled: +20 bonus\n\t- Pawn shield: +5 per pawn in front of king\n\t- Becomes less important in the endgame when king should activate \n\nCenter Control provides a bonus for pieces controlling central squares -- encouraging piece activity. \n\nMobility counts pseudo-legal moves for each piece. More moves = more options = better position. This is expensive to compute, so I made it optional with a compile-time flag.\n\n\nPart 4:  Performance Metrics \n\nPart 4.1:  Raw Search Performance\nThe engine achieves approximately 12,000-15,000 nodes per second on consumer hardware after optimizations. For context, modern engines at this strength level typically reach 50,000-500,000 nodes/second, so there's significant room for improvement. However, raw speed isn't everything - what matters more is how efficiently those nodes are being searched.\n\t\nPart 4.2:  Move Ordering Effectiveness\nThe critical metric for search efficiency is the first-move cutoff rate - how often does the first move examined at a node cause a beta cutoff, allowing us to skip searching all remaining moves?\n\nHere's how my engine performs across different position types:\n\nPosition Type:       First-Move Cutoff     Nodes/Second  \nOpening                             60.7%                     15,000\nEarly middlegame             42%                       13,500\nTactical complexity           13.7%                    6,384\nQuiet endgame                  58%                       14,800\n\nThat third row was the smoking gun. In tactically sharp positions with multiple captures available, move ordering completely broke down.\n\nPart 4.3:  The Static Exchange Evaluation (SEE) Impact\nThe problem was clear: the engine was trying captures in the wrong order. Before SEE, all captures were scored equally high (1,000,000+ points) using simple MVV-LVA (Most Valuable Victim - Least Valuable Attacker). This meant:\n\tÃ¢ÂÂ¢ Knight takes queen = 1,089,680 points \n\tÃ¢ÂÂ¢ Knight takes pawn but hangs the knight = 1,009,680 points (terrible)\nBoth captures scored over 1 million, so the bad capture was still examined before killer moves (800,000-900,000 points). In the tactical test position, this caused catastrophic move ordering. \n\nThis single optimization essentially doubled search efficiency in tactical positions by ensuring the engine examines promising moves before wasting time on captures that lose material.\n\nPart 4.4 Overall Playing Strength \nThe classical engine plays at approximately 1500 ELO based on testing against rated opponents. Key strengths:\n\tÃ¢ÂÂ¢ Solid tactical vision (rarely hangs pieces)\n\tÃ¢ÂÂ¢ Reasonable positional understanding from PST\n\tÃ¢ÂÂ¢ Good king safety in opening/middlegame\n\tÃ¢ÂÂ¢ Decent endgame technique with passed pawn evaluation\nWeaknesses:\n\tÃ¢ÂÂ¢ Occasionally misses deep combinations (6+ moves)\n\tÃ¢ÂÂ¢ Positional evaluation could be more sophisticated\n\tÃ¢ÂÂ¢ Limited opening book knowledge\n\tÃ¢ÂÂ¢ Search speed still below top engines at this level",
    "category": "tech",
    "created": "2025-12-30T15:08:01.461Z",
    "lastModified": "2025-12-30T15:08:42.909Z",
    "pinnedSlots": {
      "discourse": null,
      "tech": 1,
      "history": null,
      "literature": null
    }
  }
]